{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 3942,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03805537056417087,
      "grad_norm": 0.7838965654373169,
      "learning_rate": 1.240506329113924e-05,
      "loss": 3.0452,
      "step": 50
    },
    {
      "epoch": 0.07611074112834174,
      "grad_norm": 0.8777745962142944,
      "learning_rate": 2.5063291139240507e-05,
      "loss": 2.5626,
      "step": 100
    },
    {
      "epoch": 0.1141661116925126,
      "grad_norm": 0.9947562217712402,
      "learning_rate": 3.772151898734178e-05,
      "loss": 2.3296,
      "step": 150
    },
    {
      "epoch": 0.15222148225668347,
      "grad_norm": 1.2130990028381348,
      "learning_rate": 5.0379746835443044e-05,
      "loss": 2.2206,
      "step": 200
    },
    {
      "epoch": 0.19027685282085435,
      "grad_norm": 1.5693359375,
      "learning_rate": 6.303797468354431e-05,
      "loss": 2.144,
      "step": 250
    },
    {
      "epoch": 0.2283322233850252,
      "grad_norm": 1.4965922832489014,
      "learning_rate": 7.569620253164558e-05,
      "loss": 2.1131,
      "step": 300
    },
    {
      "epoch": 0.2663875939491961,
      "grad_norm": 1.4063897132873535,
      "learning_rate": 8.835443037974684e-05,
      "loss": 2.0632,
      "step": 350
    },
    {
      "epoch": 0.30444296451336694,
      "grad_norm": 1.6860793828964233,
      "learning_rate": 9.999968621158498e-05,
      "loss": 2.0476,
      "step": 400
    },
    {
      "epoch": 0.3424983350775378,
      "grad_norm": 1.3785202503204346,
      "learning_rate": 9.994282290227218e-05,
      "loss": 1.9976,
      "step": 450
    },
    {
      "epoch": 0.3805537056417087,
      "grad_norm": 1.423872709274292,
      "learning_rate": 9.978802875182717e-05,
      "loss": 1.9952,
      "step": 500
    },
    {
      "epoch": 0.41860907620587956,
      "grad_norm": 1.3285799026489258,
      "learning_rate": 9.953560728977584e-05,
      "loss": 1.9867,
      "step": 550
    },
    {
      "epoch": 0.4566644467700504,
      "grad_norm": 1.419445276260376,
      "learning_rate": 9.918605347905103e-05,
      "loss": 1.9568,
      "step": 600
    },
    {
      "epoch": 0.49471981733422127,
      "grad_norm": 1.307274580001831,
      "learning_rate": 9.874005274543998e-05,
      "loss": 1.9077,
      "step": 650
    },
    {
      "epoch": 0.5327751878983922,
      "grad_norm": 1.1738413572311401,
      "learning_rate": 9.819847963356092e-05,
      "loss": 1.9126,
      "step": 700
    },
    {
      "epoch": 0.570830558462563,
      "grad_norm": 1.2130571603775024,
      "learning_rate": 9.756239609200423e-05,
      "loss": 1.8676,
      "step": 750
    },
    {
      "epoch": 0.6088859290267339,
      "grad_norm": 1.2679790258407593,
      "learning_rate": 9.683304939100089e-05,
      "loss": 1.8938,
      "step": 800
    },
    {
      "epoch": 0.6469412995909047,
      "grad_norm": 1.223459243774414,
      "learning_rate": 9.601186967670107e-05,
      "loss": 1.8292,
      "step": 850
    },
    {
      "epoch": 0.6849966701550756,
      "grad_norm": 0.9854732155799866,
      "learning_rate": 9.510046716685923e-05,
      "loss": 1.8768,
      "step": 900
    },
    {
      "epoch": 0.7230520407192466,
      "grad_norm": 1.017599105834961,
      "learning_rate": 9.41006289934237e-05,
      "loss": 1.9036,
      "step": 950
    },
    {
      "epoch": 0.7611074112834174,
      "grad_norm": 1.0584486722946167,
      "learning_rate": 9.301431569822269e-05,
      "loss": 1.8345,
      "step": 1000
    },
    {
      "epoch": 0.7991627818475883,
      "grad_norm": 1.1269452571868896,
      "learning_rate": 9.1843657388618e-05,
      "loss": 1.8249,
      "step": 1050
    },
    {
      "epoch": 0.8372181524117591,
      "grad_norm": 1.0590829849243164,
      "learning_rate": 9.059094956066446e-05,
      "loss": 1.7673,
      "step": 1100
    },
    {
      "epoch": 0.87527352297593,
      "grad_norm": 1.1280231475830078,
      "learning_rate": 8.925864859796543e-05,
      "loss": 1.8159,
      "step": 1150
    },
    {
      "epoch": 0.9133288935401008,
      "grad_norm": 1.1732981204986572,
      "learning_rate": 8.784936695505066e-05,
      "loss": 1.775,
      "step": 1200
    },
    {
      "epoch": 0.9513842641042717,
      "grad_norm": 1.214943289756775,
      "learning_rate": 8.636586803472082e-05,
      "loss": 1.7989,
      "step": 1250
    },
    {
      "epoch": 0.9894396346684425,
      "grad_norm": 1.2726664543151855,
      "learning_rate": 8.481106076940394e-05,
      "loss": 1.763,
      "step": 1300
    },
    {
      "epoch": 1.027399866806203,
      "grad_norm": 1.1819242238998413,
      "learning_rate": 8.318799391714855e-05,
      "loss": 1.7124,
      "step": 1350
    },
    {
      "epoch": 1.0654552373703738,
      "grad_norm": 1.093436360359192,
      "learning_rate": 8.149985008343869e-05,
      "loss": 1.7156,
      "step": 1400
    },
    {
      "epoch": 1.1035106079345447,
      "grad_norm": 1.1899197101593018,
      "learning_rate": 7.974993948055269e-05,
      "loss": 1.7218,
      "step": 1450
    },
    {
      "epoch": 1.1415659784987156,
      "grad_norm": 1.1542738676071167,
      "learning_rate": 7.794169343670326e-05,
      "loss": 1.6989,
      "step": 1500
    },
    {
      "epoch": 1.1796213490628864,
      "grad_norm": 1.2415038347244263,
      "learning_rate": 7.607865766768615e-05,
      "loss": 1.7106,
      "step": 1550
    },
    {
      "epoch": 1.2176767196270575,
      "grad_norm": 1.1223899126052856,
      "learning_rate": 7.416448532423085e-05,
      "loss": 1.7019,
      "step": 1600
    },
    {
      "epoch": 1.2557320901912283,
      "grad_norm": 1.1468846797943115,
      "learning_rate": 7.220292982868663e-05,
      "loss": 1.7083,
      "step": 1650
    },
    {
      "epoch": 1.2937874607553992,
      "grad_norm": 1.1032288074493408,
      "learning_rate": 7.019783751508997e-05,
      "loss": 1.6658,
      "step": 1700
    },
    {
      "epoch": 1.33184283131957,
      "grad_norm": 1.0981260538101196,
      "learning_rate": 6.815314008704525e-05,
      "loss": 1.6968,
      "step": 1750
    },
    {
      "epoch": 1.369898201883741,
      "grad_norm": 1.229381799697876,
      "learning_rate": 6.607284690820776e-05,
      "loss": 1.6843,
      "step": 1800
    },
    {
      "epoch": 1.4079535724479117,
      "grad_norm": 1.1417018175125122,
      "learning_rate": 6.396103714048645e-05,
      "loss": 1.6841,
      "step": 1850
    },
    {
      "epoch": 1.4460089430120826,
      "grad_norm": 1.1459527015686035,
      "learning_rate": 6.182185174538177e-05,
      "loss": 1.693,
      "step": 1900
    },
    {
      "epoch": 1.4840643135762535,
      "grad_norm": 1.1629247665405273,
      "learning_rate": 5.965948536414361e-05,
      "loss": 1.6505,
      "step": 1950
    },
    {
      "epoch": 1.5221196841404243,
      "grad_norm": 1.1115317344665527,
      "learning_rate": 5.747817809267051e-05,
      "loss": 1.6497,
      "step": 2000
    },
    {
      "epoch": 1.5601750547045952,
      "grad_norm": 1.1475228071212769,
      "learning_rate": 5.528220716727892e-05,
      "loss": 1.6768,
      "step": 2050
    },
    {
      "epoch": 1.598230425268766,
      "grad_norm": 1.212666392326355,
      "learning_rate": 5.307587857764519e-05,
      "loss": 1.683,
      "step": 2100
    },
    {
      "epoch": 1.6362857958329369,
      "grad_norm": 1.1397391557693481,
      "learning_rate": 5.086351862336637e-05,
      "loss": 1.661,
      "step": 2150
    },
    {
      "epoch": 1.6743411663971077,
      "grad_norm": 1.1130989789962769,
      "learning_rate": 4.864946543069601e-05,
      "loss": 1.6483,
      "step": 2200
    },
    {
      "epoch": 1.7123965369612786,
      "grad_norm": 1.2420835494995117,
      "learning_rate": 4.6438060446089674e-05,
      "loss": 1.6484,
      "step": 2250
    },
    {
      "epoch": 1.7504519075254494,
      "grad_norm": 1.1543350219726562,
      "learning_rate": 4.423363992323991e-05,
      "loss": 1.6384,
      "step": 2300
    },
    {
      "epoch": 1.7885072780896203,
      "grad_norm": 1.0726383924484253,
      "learning_rate": 4.204052642029355e-05,
      "loss": 1.6026,
      "step": 2350
    },
    {
      "epoch": 1.8265626486537911,
      "grad_norm": 1.2244648933410645,
      "learning_rate": 3.986302032392404e-05,
      "loss": 1.6424,
      "step": 2400
    },
    {
      "epoch": 1.864618019217962,
      "grad_norm": 1.1910713911056519,
      "learning_rate": 3.770539141687881e-05,
      "loss": 1.6379,
      "step": 2450
    },
    {
      "epoch": 1.9026733897821329,
      "grad_norm": 1.1931273937225342,
      "learning_rate": 3.557187050553682e-05,
      "loss": 1.6408,
      "step": 2500
    },
    {
      "epoch": 1.940728760346304,
      "grad_norm": 1.1964153051376343,
      "learning_rate": 3.346664112389313e-05,
      "loss": 1.631,
      "step": 2550
    },
    {
      "epoch": 1.9787841309104748,
      "grad_norm": 1.2574487924575806,
      "learning_rate": 3.139383133023801e-05,
      "loss": 1.64,
      "step": 2600
    },
    {
      "epoch": 2.016744363048235,
      "grad_norm": 1.1958677768707275,
      "learning_rate": 2.9357505612616066e-05,
      "loss": 1.61,
      "step": 2650
    },
    {
      "epoch": 2.054799733612406,
      "grad_norm": 1.163960337638855,
      "learning_rate": 2.736165691893765e-05,
      "loss": 1.5875,
      "step": 2700
    },
    {
      "epoch": 2.092855104176577,
      "grad_norm": 1.1701031923294067,
      "learning_rate": 2.5410198827370464e-05,
      "loss": 1.5722,
      "step": 2750
    },
    {
      "epoch": 2.1309104747407477,
      "grad_norm": 1.1677749156951904,
      "learning_rate": 2.350695787236406e-05,
      "loss": 1.56,
      "step": 2800
    },
    {
      "epoch": 2.1689658453049185,
      "grad_norm": 1.2088686227798462,
      "learning_rate": 2.165566604135463e-05,
      "loss": 1.5698,
      "step": 2850
    },
    {
      "epoch": 2.2070212158690894,
      "grad_norm": 1.221201777458191,
      "learning_rate": 1.9859953456863467e-05,
      "loss": 1.5614,
      "step": 2900
    },
    {
      "epoch": 2.2450765864332602,
      "grad_norm": 1.2301956415176392,
      "learning_rate": 1.8123341258337807e-05,
      "loss": 1.5387,
      "step": 2950
    },
    {
      "epoch": 2.283131956997431,
      "grad_norm": 1.1613305807113647,
      "learning_rate": 1.6449234697692563e-05,
      "loss": 1.5208,
      "step": 3000
    },
    {
      "epoch": 2.321187327561602,
      "grad_norm": 1.3012661933898926,
      "learning_rate": 1.4840916462090804e-05,
      "loss": 1.527,
      "step": 3050
    },
    {
      "epoch": 2.359242698125773,
      "grad_norm": 1.2734668254852295,
      "learning_rate": 1.3301540237056632e-05,
      "loss": 1.5441,
      "step": 3100
    },
    {
      "epoch": 2.3972980686899437,
      "grad_norm": 1.117715835571289,
      "learning_rate": 1.183412452254215e-05,
      "loss": 1.5437,
      "step": 3150
    },
    {
      "epoch": 2.435353439254115,
      "grad_norm": 1.1504030227661133,
      "learning_rate": 1.0441546714074074e-05,
      "loss": 1.5554,
      "step": 3200
    },
    {
      "epoch": 2.4734088098182854,
      "grad_norm": 1.1832499504089355,
      "learning_rate": 9.12653746058657e-06,
      "loss": 1.5395,
      "step": 3250
    },
    {
      "epoch": 2.5114641803824567,
      "grad_norm": 1.1833134889602661,
      "learning_rate": 7.89167531000316e-06,
      "loss": 1.5596,
      "step": 3300
    },
    {
      "epoch": 2.549519550946627,
      "grad_norm": 1.2615256309509277,
      "learning_rate": 6.739381653067528e-06,
      "loss": 1.5851,
      "step": 3350
    },
    {
      "epoch": 2.5875749215107984,
      "grad_norm": 1.256187915802002,
      "learning_rate": 5.671915975337333e-06,
      "loss": 1.5365,
      "step": 3400
    },
    {
      "epoch": 2.6256302920749692,
      "grad_norm": 1.230812668800354,
      "learning_rate": 4.691371426651186e-06,
      "loss": 1.5244,
      "step": 3450
    },
    {
      "epoch": 2.66368566263914,
      "grad_norm": 1.192383885383606,
      "learning_rate": 3.7996707167567925e-06,
      "loss": 1.561,
      "step": 3500
    },
    {
      "epoch": 2.701741033203311,
      "grad_norm": 1.2444502115249634,
      "learning_rate": 2.9985623451478204e-06,
      "loss": 1.5444,
      "step": 3550
    },
    {
      "epoch": 2.739796403767482,
      "grad_norm": 1.271973729133606,
      "learning_rate": 2.289617172502778e-06,
      "loss": 1.5556,
      "step": 3600
    },
    {
      "epoch": 2.7778517743316526,
      "grad_norm": 1.2021830081939697,
      "learning_rate": 1.6742253404483877e-06,
      "loss": 1.4937,
      "step": 3650
    },
    {
      "epoch": 2.8159071448958235,
      "grad_norm": 1.1981302499771118,
      "learning_rate": 1.1535935456877533e-06,
      "loss": 1.5466,
      "step": 3700
    },
    {
      "epoch": 2.8539625154599944,
      "grad_norm": 1.1963828802108765,
      "learning_rate": 7.287426738380232e-07,
      "loss": 1.5323,
      "step": 3750
    },
    {
      "epoch": 2.892017886024165,
      "grad_norm": 1.3279457092285156,
      "learning_rate": 4.005057976175175e-07,
      "loss": 1.5697,
      "step": 3800
    },
    {
      "epoch": 2.930073256588336,
      "grad_norm": 1.278043270111084,
      "learning_rate": 1.6952654330748552e-07,
      "loss": 1.539,
      "step": 3850
    },
    {
      "epoch": 2.968128627152507,
      "grad_norm": 1.257055640220642,
      "learning_rate": 3.625782869156602e-08,
      "loss": 1.5109,
      "step": 3900
    }
  ],
  "logging_steps": 50,
  "max_steps": 3942,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.984845971113902e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
