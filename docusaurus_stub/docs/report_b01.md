---
title: report_b01_vector_database_tutorial
---

---
## Vector database concepts
---

### Definitions and core ideas
<details>
<summary>Essential definitions, mental models, and when to use a vector database</summary>

---

- **Embeddings (vectors)**
  - Dense numeric arrays encoding semantics (text, images, audio, multimodal).
  - Similarity computed using metrics such as `cosine`, `dot`, or `L2`.
  - Generated by embedding models (e.g., `sentence-transformers/*`, OpenAI, Cohere, Voyage, NVIDIA, local HF models).
- **Vector database**
  - Purpose-built system to store vectors + metadata, and to perform approximate nearest neighbor (`ANN`) similarity search at scale.
  - Adds durability, filtering, pagination, access control, observability, and horizontal scaling beyond in-memory libraries (e.g., FAISS).
- **Indexing**
  - Structures (e.g., `HNSW`, IVF variants, PQ/SQ quantization) to accelerate search.
  - Trade-off triangle: recall ↔ latency ↔ memory.
- **Distance metrics**
  - `cosine` for angle-based similarity, `dot` for magnitude-aware semantics, `L2` for Euclidean distance.
  - Choose based on embedding training objective and downstream evaluation.
- **Typical use cases**
  - RAG for documents and code.
  - Semantic search + metadata faceting.
  - Recommendations, deduplication, clustering, anomaly detection.
  - Hybrid retrieval (dense + keyword/sparse) for precision + recall coverage.
- **Why not just FAISS?**
  - FAISS is a great library for local indexing; a vector database adds multi-tenant collections, payload filtering, hybrid search, durability, replication, backup/snapshots, and APIs/SDKs.

#### mental_models

- **Retrieval path**
  - Ingest → chunk → embed → store `(vector, payload)` → index → search → optional re-ranking → application.
- **RAG path**
  - User question → embed query → vector search with filters → gather top-`k` contexts → craft prompt → call LLM → stream answer with citations.

---

</details>

### Tool landscape overview
<details>
<summary>Popular options and quick positioning</summary>

---

- **Qdrant**
  - Open-source + Cloud; strong payload filtering; named vectors; hybrid/multi-stage queries; snapshots; REST + gRPC; easy Docker.
- **Weaviate**
  - Open-source + Cloud; robust hybrid (BM25 + vector) search and fusion controls; modules; filters; replication.
- **Milvus**
  - Open-source + managed (Zilliz Cloud); wide index coverage (HNSW, IVF, DiskANN, SCANN) and scale; scalar fields; partitions.
- **Pinecone**
  - Managed serverless; namespaces; high availability; focus on simplicity and operational SLAs; cloud-only.
- **Chroma**
  - Open-source + Cloud; very simple local dev story; tight Python ergonomics; good for prototypes and smaller apps.

#### Selection criteria

- **Workload shape**
  - `QPS`, vector dimension, `k`, read/write mix, filter selectivity, hybrid need, multi-vector need.
- **Ops requirements**
  - Managed vs self-hosted, budget, data residency, security, snapshots/backup, monitoring.
- **Developer fit**
  - SDK coverage, documentation quality, community, ecosystem integrations (LangChain, LlamaIndex, custom).

---

</details>

---
## Tool comparison
---

### Comparison matrix
<details>
<summary>Feature-by-feature matrix (condensed, implementation-driven)</summary>

---

- Feature notes
  - Features reflect current product docs; verify during selection and PoC.

| **Capability** | Qdrant | Weaviate | Milvus | Pinecone | Chroma |
|---|---|---|---|---|---|
| **License / Hosting** | OSS + Cloud | OSS + Cloud | OSS + Zilliz Cloud | Managed only | OSS + Cloud |
| **Hybrid search** | Dense + sparse via Query API (RRF/DBSF) | BM25 + vector, `alpha` blending | Sparse/dense + scalar filters | Metadata filters; hybrid via patterns | Keyword + dense via client patterns |
| **Index types** | HNSW + quantization | HNSW + compression | HNSW, IVF*, DiskANN, SCANN | Managed internal | HNSW-like |
| **Filtering** | Payload filters + payload indexes | Property filters | Scalar filters, partitions | Metadata filters | Metadata filters |
| **Multivector / Named vectors** | Yes | Class-based multi-vector | Multi-field vectors | Per-record vector | Single vector (typ.) |
| **APIs** | REST, gRPC, SDKs | GraphQL, REST, clients | gRPC, REST, SDKs | REST, SDKs | Python, HTTP |
| **Ops** | Snapshots, monitoring, distributed | Replication, modules | Horizontal scale, compaction | Serverless, namespaces | Simple local dev |

  - Practical notes:
    - Qdrant hybrid/multi-stage query fusion and payload indexes enable fast filtered retrieval and dense+sparse fusion.
    - Weaviate’s hybrid fusion (`relativeScoreFusion`, `rankedFusion`) gives explicit BM25 + vector blending control.
    - Milvus offers the broadest index family and both in-memory and on-disk search paths.
    - Pinecone serverless emphasizes operational simplicity and separation of control/data planes.
    - Chroma is the quickest path to a prototype or small-to-mid app with local-first ergonomics.

---

</details>

### Decision framework
<details>
<summary>How to choose for your project</summary>

---

- **If you want simple, fast local dev with strong filtering and hybrid fusion** → Qdrant.
- **If you need BM25 + vector hybrid with explicit `alpha`** → Weaviate.
- **If scale and index variety are paramount (billions, GPU/on-disk, partitions)** → Milvus (or Zilliz Cloud).
- **If you prefer fully managed, serverless ops + multi-region SLAs** → Pinecone.
- **If you’re prototyping and want minimal dependencies** → Chroma.

#### Risk and exit costs

- **Lock-in**
  - Managed-only vendors add exit costs; plan a migration path (export vectors + metadata, re-indexing time).
- **Evolving APIs**
  - SDKs and APIs evolve; pin versions and keep compatibility tests in CI.
- **Hybrid expectations**
  - Validate hybrid quality with your text distribution; tune `alpha`, fusion method, and filtering precision.

---

</details>

---
## Deep dive: Qdrant
---

### Why Qdrant for this tutorial
<details>
<summary>Rationale for selection and scenarios where Qdrant shines</summary>

---

- **Fast to start locally** with Docker; great for teams that want a working POC in minutes.
- **Strong metadata filtering** with payload indexes for low-latency faceted search.
- **Named vectors + hybrid/multi-stage queries** to combine dense and sparse signals cleanly.
- **Production features** such as snapshots, async ops, and monitoring hooks.
- **Great SDK coverage** across Python/TS/Rust/Java/C#/Go.

---

</details>

### Architecture and data model
<details>
<summary>Collections, points, vectors, payload, and a RAG dataflow (diagram)</summary>

---

- **Data model**
  - Collection → Points → `{ id, vector(s), payload }`.
  - Payload carries rich metadata (e.g., `source`, `url`, `tags`, `created_at`).
- **RAG with Qdrant (Mermaid)**
  - Diagram:

  -
    ```mermaid
    graph LR
      A[Raw docs] --> B[Chunking]
      B --> C[Embeddings]
      C --> D[(Qdrant: vectors + payload)]
      E[Query] --> F[Embed query]
      F --> G{Filters?}
      G -->|yes| H[Filter by payload indexes]
      G -->|no| D
      H --> D
      D --> I[Top-k results]
      I --> J[Rerank / Fusion]
      J --> K[LLM prompt + answer]
    ```

---

</details>

### Local setup with Docker
<details>
<summary>Start Qdrant locally (Docker) + verify health</summary>

---

- **Run container**
```md
    docker pull qdrant/qdrant
    docker run -p 6333:6333 -p 6334:6334 \
      -v "$(pwd)/qdrant_storage:/qdrant/storage:z" \
      qdrant/qdrant
    ```
- **Endpoints**
  - REST API `http://localhost:6333`, Web UI `http://localhost:6333/dashboard`, gRPC `:6334`.
- **Security note**
  - Default container starts without auth/TLS; secure before exposing beyond localhost.

---

</details>

### Python client quickstart
<details>
<summary>Create collection, upsert vectors + payload, and query</summary>

---

- **Install client + embeddings**
```md
    pip install qdrant-client sentence-transformers
    ```
- **Initialize client**
    ```python
    from qdrant_client import QdrantClient
    from qdrant_client.models import Distance, VectorParams, PointStruct

    client = QdrantClient(url="http://localhost:6333")

    client.create_collection(
      collection_name="docs",
      vectors_config=VectorParams(size=384, distance=Distance.COSINE),
    )
    ```
- **Prepare toy data + embeddings**
    ```python
    from sentence_transformers import SentenceTransformer
    import itertools

    model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

    texts = [
      {"id": 1, "text": "Qdrant is a vector database for semantic search.", "source": "kb", "tags": ["qdrant", "db"]},
      {"id": 2, "text": "Hybrid search mixes BM25 keywords and dense vectors.", "source": "kb", "tags": ["hybrid"]},
      {"id": 3, "text": "Payload indexes make filtered search faster.", "source": "notes", "tags": ["filter"]},
    ]

    embeddings = model.encode([t["text"] for t in texts]).tolist()
    points = [
      PointStruct(id=t["id"], vector=vec, payload=t)
      for t, vec in zip(texts, embeddings)
    ]
    ```
- **Upsert points**
    ```python
    client.upsert(collection_name="docs", points=points, wait=True)
    ```
- **Basic similarity query**
    ```python
    results = client.query_points(
      collection_name="docs",
      query=model.encode("What is Qdrant?").tolist(),
      limit=3,
      with_payload=True,
    ).points

    for r in results:
      print(r.score, r.payload["text"])
    ```
- **Filtered search by payload**
    ```python
    from qdrant_client.models import Filter, FieldCondition, MatchValue

    results = client.query_points(
      collection_name="docs",
      query=model.encode("how to speed up filtered search").tolist(),
      query_filter=Filter(must=[FieldCondition(key="source", match=MatchValue(value="kb"))]),
      limit=5,
      with_payload=True,
    ).points
    ```

---

</details>

### Payload indexing for fast filters
<details>
<summary>Create payload indexes on frequently filtered fields</summary>

---

- **Why**
  - Indexing payload fields (e.g., `source`, `tags`) speeds up filtered search substantially.
- **Create indexes**
    ```python
    from qdrant_client.models import PayloadSchemaType

    client.create_payload_index(
      collection_name="docs",
      field_name="source",
      field_schema=PayloadSchemaType.KEYWORD,
    )

    client.create_payload_index(
      collection_name="docs",
      field_name="tags",
      field_schema=PayloadSchemaType.KEYWORD,
    )
    ```
- **Practical tip**
  - Index fields that most reduce the candidate set; avoid indexing high-cardinality fields unless needed.

---

</details>

### Hybrid and multistage queries
<details>
<summary>Combine dense and sparse vectors via fusion; two-stage rescoring</summary>

---

- **Use cases**
  - Keyword-sensitive domains (legal, support) benefit from dense + sparse fusion.
- **Example (dense + sparse, `RRF` fusion)**

    ```python
    from qdrant_client import models as qm

    client.query_points(
      collection_name="docs",
      prefetch=[
        qm.Prefetch(
          query=qm.SparseVector(indices=[1, 42], values=[0.22, 0.8]),
          using="sparse",
          limit=50,
        ),
        qm.Prefetch(
          query=model.encode("hybrid search").tolist(),
          using="dense",
          limit=50,
        ),
      ],
      query=qm.FusionQuery(fusion=qm.Fusion.RRF),
      limit=10,
      with_payload=True,
    )
    ```
- **Two-stage rescoring**
  - Fetch many candidates using a cheaper representation; rescore with a larger or multi-vector model for final `top-k`.

---

</details>

### Ops checklist and snapshots
<details>
<summary>Snapshots, backups, version pinning, and basic monitoring</summary>

---

- **Snapshots**
  - Automate snapshots for collections; store off-box; validate restore in CI.
- **Versioning**
  - Pin the Docker image tag and Python client version; record in `/ops/versions.md`.
- **Metrics**
  - Track `latency`, `QPS`, `recall@k`, segment counts, RAM usage; emit to Prometheus/Grafana.
- **Capacity planning**
  - Estimate dimension × bytes per float × count; include HNSW overhead for `M` and `ef`. Test with real `k` and filters.

---

</details>

---
## Implementation guides
---

### Minimal project template
<details>
<summary>Folders, env, scripts, and a makefile to spin up quickly</summary>

---

- **Structure**

    | **Path** | **Purpose** |
    |---|---|
    | **/data/** | Input documents (txt, md, pdf extracted). |
    | **/scripts/** | Ingestion and maintenance scripts. |
    | **/notebooks/** | Exploration and evaluation. |
    | **/ops/** | Snapshots, versions, dashboards. |
    | **/app/** | RAG service (API, prompts, UI). |
- **Makefile (sample)**

    ```makefile
    up:
    	docker run -d --name qdrant -p 6333:6333 -p 6334:6334 \
    	  -v $(PWD)/qdrant_storage:/qdrant/storage:z qdrant/qdrant

    down:
    	docker rm -f qdrant || true
    ```
- **.env**

    ```bash
    QDRANT_URL=http://localhost:6333
    EMBED_MODEL=sentence-transformers/all-MiniLM-L6-v2
    ```

---

</details>

### RAG integration examples
<details>
<summary>Retriever + prompt assembly with LangChain (swap LLM provider as needed)</summary>

---

- **Install RAG deps**

    ```bash
    pip install langchain langchain-community tiktoken
    ```
- **Simple retriever over Qdrant**

    ```python
    from langchain_community.vectorstores import Qdrant
    from langchain_community.embeddings import HuggingFaceEmbeddings

    hf = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    vs = Qdrant.from_texts(
      [t["text"] for t in texts],
      hf,
      url="http://localhost:6333",
      collection_name="docs",
      metadatas=[{"source": t["source"], "tags": t["tags"]} for t in texts],
    )

    retriever = vs.as_retriever(search_kwargs={"k": 5})
    docs = retriever.get_relevant_documents("Explain payload indexes")
    for d in docs:
      print(d.metadata, d.page_content[:80])
    ```
- **Prompt assembly (pseudo)**
  - Bullet:
    - Build a system prompt template that includes instructions, answer style, and citation rules.
    - Concatenate retrieved contexts with per-chunk metadata.
    - Call your LLM via provider SDK (OpenAI, Anthropic, Gemini, etc.) with streaming enabled.

---

</details>

### Evaluation and quality
<details>
<summary>Measuring retrieval quality and correctness</summary>

---

- **Retrieval metrics**
  - `recall@k`, `precision@k`, `hit@k` with labeled query–relevant sets.
- **Ablations to run**
  - Chunk size/overlap, `k`, filter selectivity, index params (`M`, `ef`), fusion strategy.
- **Runtime metrics**
  - P50/P95 latency, throughput, memory; ingestion throughput.
- **Guardrails**
  - Source-aware answers with citations; refusal rules for unknown coverage.

---

</details>

---
## Best practices
---

### Ingestion and chunking
<details>
<summary>Preparing data for high-quality retrieval</summary>

---

- **Chunking**
  - Use semantic-aware or structural chunking when available; default to `~500` tokens with `~50` overlap for text, then tune.
- **Normalization**
  - Lowercasing, Unicode normalization, whitespace cleanup; preserve section hierarchy in payload.
- **Metadata**
  - Add fields you plan to filter on (`source`, `type`, `lang`, `tags`, `created_at`).

---

</details>

### Indexing and performance
<details>
<summary>Index choices, parameters, and latency–recall tuning</summary>

---

- **HNSW tips**
  - Increase `M` and `ef` for better recall (higher memory cost). Start with defaults, then profile with your queries.
- **Quantization**
  - Scalar/product quantization can reduce memory; evaluate quality impact on your domain.
- **Payload indexes**
  - Create keyword or numeric payload indexes for highly selective filters; benchmark with and without.

---

</details>

### Hybrid search guidance
<details>
<summary>When and how to combine lexical and semantic signals</summary>

---

- **When to use hybrid**
  - When exact term matching matters (IDs, part numbers, legal clauses) and semantics alone miss intent.
- **Fusion configuration**
  - Tune fusion method and `alpha`/weights; consider post-LLM reranking for tie-breaks.

---

</details>

### Security and governance
<details>
<summary>Access control, PII handling, backups, and audit</summary>

---

- **Access**
  - Do not expose unauthenticated Qdrant beyond localhost; add auth, TLS, and network policies.
- **PII**
  - Hash or redact sensitive fields; use payload flags to exclude from retrieval.
- **Backups**
  - Schedule snapshots; test restores regularly; encrypt at rest and in transit where supported.

---

</details>

---
## Troubleshooting and FAQ
---

### Common issues
<details>
<summary>Symptoms, causes, and fixes</summary>

---

- **High latency with filters**
  - Missing payload index; create indexes on selective fields.
- **OOM during ingestion**
  - Batch uploads; tune `HNSW` parameters; consider quantization.
- **Low recall**
  - Increase `k` and `ef`; verify distance metric matches embedding model; improve chunking.

---

</details>

---
## Glossary
---

### Terms
<details>
<summary>Standardized terminology for this report</summary>

---

- **ANN** — Approximate Nearest Neighbors.
- **HNSW** — Hierarchical Navigable Small Worlds, a graph index for fast similarity search.
- **Payload** — Record metadata stored alongside vectors, used for filtering/faceting.
- **RAG** — Retrieval-Augmented Generation, combining retrieval with LLM generation.
- **Fusion** — Method to combine multiple search signals (dense, sparse, keyword).

---

</details>

---
## References and links
---

### Official docs and key articles
<details>
<summary>Docs used to ground examples and avoid hallucination</summary>

---

- **Qdrant local quickstart** — Docker run, Python client flow, filter query.
  - Notes align with the example commands and `query_points` usage.
- **Qdrant hybrid & multi-stage queries** — `RRF`/`DBSF` fusion with named vectors and `prefetch`.
- **Qdrant payload concepts & indexing** — filtering strategies and payload indexes.
- **Weaviate hybrid search** — BM25 + vector fusion and `alpha` control.
- **Milvus index families** — breadth of index options including `HNSW`, IVF variants, on-disk indexes.
- **Pinecone serverless architecture** — namespacing and slab/object storage details.
- **Chroma getting started** — local-first ergonomics for prototypes.

---

</details>

---
## Evaluation suite
---

### Offline evaluation and reporting
<details>
<summary>Dataset format, metrics, scripts, and CI hooks to measure retrieval quality</summary>

---

- Dataset format (JSONL)
  ```json
  {"qid":"q001","query":"how to speed up filtered search","positives":["doc_12","doc_87"],"filters":{"source":"kb"}}

- Save to `data/eval/queries.jsonl`.

- Documents manifest: `data/eval/corpus.jsonl` with `id`, `text`, `metadata`.

- Metrics

  - `recall@k`, `precision@k`, `hit@k`, `MRR@k`.

  - Latency P50 and P95.

  - Ingestion throughput.

- Precompute query embeddings

    ```python
    # scripts/precompute_query_embeddings.py
    import json, sys
    from sentence_transformers import SentenceTransformer

    m = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
    with open(sys.argv[1], "r", encoding="utf-8") as f:
        for line in f:
            row = json.loads(line)
            row["query_embedding"] = m.encode(row["query"]).tolist()
            print(json.dumps(row, ensure_ascii=False))
    ```

- Evaluation script

    ```python
    # scripts/run_eval.py
    import json, time, statistics as stats
    from qdrant_client import QdrantClient
    from qdrant_client.models import Filter, FieldCondition, MatchValue

    def load_jsonl(path):
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                yield json.loads(line)

    client = QdrantClient(url="http://localhost:6333")

    queries = list(load_jsonl("data/eval/queries_with_emb.jsonl"))
    lat = []
    hit = {5:0, 10:0, 20:0}
    total = len(queries)

    for q in queries:
        t0 = time.perf_counter()
        flt = None
        if "filters" in q:
            flt = Filter(must=[FieldCondition(key=k, match=MatchValue(value=v)) for k, v in q["filters"].items()])
        res = client.query_points(
            collection_name="docs",
            query=q["query_embedding"],
            query_filter=flt,
            limit=20, with_payload=False,
        ).points
        lat.append((time.perf_counter() - t0) * 1000.0)
        ids = [str(r.id) for r in res]
        for k in hit:
            if any(pid in ids[:k] for pid in q["positives"]):
                hit[k] += 1

    print("P50(ms)=", stats.median(lat))
    print("P95(ms)=", sorted(lat)[int(0.95 * len(lat)) - 1])
    for k, v in hit.items():
        print(f"hit@{k}=", v / total)
        
    ```

- Makefile target

    ```makefile
    eval:
      python scripts/precompute_query_embeddings.py data/eval/queries.jsonl > data/eval/queries_with_emb.jsonl
      python scripts/run_eval.py
    ```
- Reporting
    ```md
    date,build_sha,collection,p95_ms,hit@5,hit@10,hit@20,notes
    ```
  - Export CSV to `reports/`.

  - Plot trend charts in `reports/` (optional).

- Tips

  - Maintain a small canary set curated by SMEs.

  - Add A/B runs for hybrid weights and reranker on/off.

  - Gate releases on hit@5 and P95 thresholds.
  
---

  </details>

---
## Security and compliance
---

### Transport and identity controls
<details>
<summary>TLS termination, mTLS internal traffic, API keys, and PII handling playbook</summary>

---

- TLS termination (Ingress/controller)
  - Enforce HTTPS, enable HSTS, and use short-lived certificates (ACME).

- mTLS for east-west traffic
  - Use a service mesh (Istio/Linkerd) for peer authentication and frequent certificate rotation.

- API keys & scopes
  - Enforce API keys at the gateway with per-route scopes; apply per-tenant rate limits; keep audit logs for `/ingest` and `/search`.

- PII policy
  - Redact/hash sensitive fields at ingestion; support a “do-not-index” flag in payload; maintain access logs.

- Backups & retention
  - Encrypt snapshots at rest; define retention schedules; run regular restore drills.

- Nginx ingress (example)
  ```nginx
  server {
    listen 443 ssl http2;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
    location / {
      proxy_pass http://qdrant:6333;
      proxy_set_header X-API-Key $http_x_api_key;
    }
  }

---

</details>

---
## Multi-tool code appendix
---

### Weaviate and Milvus examples
<details>
<summary>Hybrid BM25+vector in Weaviate and HNSW/IVF search in Milvus (minimal runnable snippets)</summary>

---

- Weaviate hybrid (Python client)
  ```bash
  pip install weaviate-client
  ```

  ```python
  import weaviate
  from weaviate.classes.query import Hybrid

  client = weaviate.Client("http://localhost:8080")
  res = client.collections.get("Docs").query.hybrid(
      query="payload indexes",
      alpha=0.6,
      limit=5
  )
  print(res.objects)
  ```

- Milvus HNSW / IVF (PyMilvus)
  ```bash
  pip install pymilvus
  ```

  ```python
  from pymilvus import connections, FieldSchema, CollectionSchema, DataType, Collection

  connections.connect("default", host="localhost", port="19530")

  fields = [
      FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
      FieldSchema(name="vec", dtype=DataType.FLOAT_VECTOR, dim=384),
      FieldSchema(name="source", dtype=DataType.VARCHAR, max_length=16),
  ]
  schema = CollectionSchema(fields, description="docs")
  col = Collection("docs", schema)

  index_params = {"index_type": "HNSW", "metric_type": "IP", "params": {"M": 16, "efConstruction": 200}}
  col.create_index(field_name="vec", index_params=index_params)
  col.load()
  ```
  
  ```python
  import numpy as np

  q = np.random.rand(1, 384).astype("float32")
  res = col.search(
      q,
      "vec",
      param={"metric_type": "IP", "params": {"ef": 128}},
      limit=5,
      expr='source == "kb"',
  )
  print(res)
  ```
---

</details>